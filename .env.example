# Application
APP_ENV=development
DEBUG=true
SECRET_KEY=your-super-secret-key-change-in-production

# Database
DATABASE_URL=postgresql://n9r:n9r_dev_password@localhost:5432/n9r

# Redis
REDIS_URL=redis://localhost:6379/0

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=n9r-dev

# GitHub App
GITHUB_APP_ID=123456
GITHUB_CLIENT_ID=Iv1.xxxxxxxxxxxx
GITHUB_CLIENT_SECRET=xxxxxxxxxxxxxxxxxxxx
GITHUB_PRIVATE_KEY_PATH=./github-app.pem
GITHUB_WEBHOOK_SECRET=your-webhook-secret

# =============================================================================
# LLM Gateway Configuration (via LiteLLM)
# =============================================================================
# Uncomment and configure ONE provider for embeddings and chat.
# LiteLLM supports 100+ providers with unified API.
# Docs: https://docs.litellm.ai/docs/providers

# -----------------------------------------------------------------------------
# Option 1: OpenAI (Recommended - simplest setup)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
# Models: gpt-4o, gpt-4o-mini, gpt-4-turbo, o1-preview
# Embeddings: text-embedding-3-small, text-embedding-3-large

# -----------------------------------------------------------------------------
# Option 2: Azure OpenAI
# -----------------------------------------------------------------------------
# AZURE_API_KEY=your-azure-openai-api-key
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-15-preview
# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
# AZURE_CHAT_DEPLOYMENT=gpt-4o
# 
# Find these in Azure Portal:
# - API Key: Azure Portal → OpenAI resource → Keys and Endpoint
# - API Base: Same page → Endpoint URL
# - Deployments: Azure OpenAI Studio → Deployments

# -----------------------------------------------------------------------------
# Option 3: AWS Bedrock
# -----------------------------------------------------------------------------
# Uses AWS credentials from environment or ~/.aws/credentials
# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key
# AWS_REGION_NAME=us-east-1
#
# Models (use bedrock/ prefix):
# - bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
# - bedrock/anthropic.claude-3-haiku-20240307-v1:0
# - bedrock/amazon.titan-embed-text-v2:0
# - bedrock/cohere.embed-english-v3
#
# To use Bedrock, set:
# DEFAULT_LLM_MODEL=bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
# BEDROCK_EMBEDDING_MODEL=bedrock/amazon.titan-embed-text-v2:0
# for sonnet 4.5 to use 1 mln context
# ANTHROPIC_BETA_CONTEXT_HEADER=context-1m-2025-08-07

# -----------------------------------------------------------------------------
# Option 4: Google Cloud Vertex AI
# -----------------------------------------------------------------------------
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
# VERTEX_PROJECT=your-gcp-project-id
# VERTEX_LOCATION=us-central1
#
# Models (use vertex_ai/ prefix):
# please use gemini-3-pro-preview
#
# To use Vertex AI, set:
# DEFAULT_LLM_MODEL=vertex_ai/gemini-1.5-pro
# VERTEX_EMBEDDING_MODEL=vertex_ai/text-embedding-004

# -----------------------------------------------------------------------------
# Option 5: Google AI Studio (Gemini - simpler than Vertex)
# -----------------------------------------------------------------------------
# GEMINI_API_KEY=your-gemini-api-key
#
# Chat models:
# please use gemini-3-pro-preview
#
# Embedding models:
# - text-embedding-004 (768 dimensions, latest)
#
# Get API key: https://aistudio.google.com/apikey
# Docs: https://ai.google.dev/gemini-api/docs

# -----------------------------------------------------------------------------
# Option 6: Anthropic (Claude)
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxx
# Models: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
# Note: Anthropic doesn't have embedding models, use with OpenAI/other for embeddings

# -----------------------------------------------------------------------------
# Option 7: OpenRouter (Access 100+ models via single API)
# -----------------------------------------------------------------------------
# OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxx
#
# Models (use openrouter/ prefix):
# - openrouter/anthropic/claude-3.5-sonnet
# - openrouter/openai/gpt-4o
# - openrouter/google/gemini-pro
# - openrouter/meta-llama/llama-3.1-405b-instruct
#
# Get API key: https://openrouter.ai/keys
# Browse models: https://openrouter.ai/models

# -----------------------------------------------------------------------------
# Default Provider Settings
# -----------------------------------------------------------------------------
DEFAULT_LLM_PROVIDER=openai
DEFAULT_LLM_MODEL=gpt-4o

# Examples for other providers:
# DEFAULT_LLM_MODEL=azure/your-deployment-name
# DEFAULT_LLM_MODEL=bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
# DEFAULT_LLM_MODEL=vertex_ai/gemini-1.5-pro
# DEFAULT_LLM_MODEL=gemini/gemini-2.0-flash-exp
# DEFAULT_LLM_MODEL=anthropic/claude-3-5-sonnet-20241022
# DEFAULT_LLM_MODEL=openrouter/anthropic/claude-3.5-sonnet

# Embedding model override (optional - auto-detected based on provider)
# EMBEDDING_MODEL=openai/text-embedding-3-small
# EMBEDDING_MODEL=azure/text-embedding-ada-002
# EMBEDDING_MODEL=bedrock/amazon.titan-embed-text-v2:0
# EMBEDDING_MODEL=vertex_ai/text-embedding-004

# Celery
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# Sandbox (for Docker deployment only)
# When running Celery inside Docker, configure these paths:
# SANDBOX_ROOT_DIR: Base directory for sandbox workdirs inside Celery container
# HOST_SANDBOX_PATH: Corresponding path on Docker host for volume mounting
# For local development, leave these empty (defaults to /tmp)
SANDBOX_ROOT_DIR=
HOST_SANDBOX_PATH=
# Example for Docker deployment:
# SANDBOX_ROOT_DIR=/app/sandbox_data
# HOST_SANDBOX_PATH=/absolute/path/to/project/sandbox_data

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000/v1
NEXT_PUBLIC_APP_URL=http://localhost:3000
NEXT_PUBLIC_GITHUB_CLIENT_ID=Iv1.xxxxxxxxxxxx
SESSION_SECRET=your-session-secret-at-least-32-chars-long
