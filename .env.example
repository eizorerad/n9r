# Application
APP_ENV=development
DEBUG=true
SECRET_KEY=your-super-secret-key-change-in-production

# Database
DATABASE_URL=postgresql://n9r:n9r_dev_password@localhost:5432/n9r

# Redis
REDIS_URL=redis://localhost:6379/0

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=n9r-dev

# GitHub App
GITHUB_APP_ID=123456
GITHUB_CLIENT_ID=Iv1.xxxxxxxxxxxx
GITHUB_CLIENT_SECRET=xxxxxxxxxxxxxxxxxxxx
GITHUB_PRIVATE_KEY_PATH=./github-app.pem
GITHUB_WEBHOOK_SECRET=your-webhook-secret

# =============================================================================
# LLM Gateway Configuration (via LiteLLM)
# =============================================================================
# Uncomment and configure ONE provider for embeddings and chat.
# LiteLLM supports 100+ providers with unified API.
# Docs: https://docs.litellm.ai/docs/providers

# -----------------------------------------------------------------------------
# Option 1: OpenAI (Recommended - simplest setup)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
# Models: gpt-4o, gpt-4o-mini, gpt-4-turbo, o1-preview
# Embeddings: text-embedding-3-small, text-embedding-3-large

# -----------------------------------------------------------------------------
# Option 2: Azure OpenAI
# -----------------------------------------------------------------------------
# AZURE_API_KEY=your-azure-openai-api-key
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-15-preview
# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
# AZURE_CHAT_DEPLOYMENT=gpt-4o
# 
# Find these in Azure Portal:
# - API Key: Azure Portal → OpenAI resource → Keys and Endpoint
# - API Base: Same page → Endpoint URL
# - Deployments: Azure OpenAI Studio → Deployments

# -----------------------------------------------------------------------------
# Option 3: AWS Bedrock (Claude Sonnet 4.5 - RECOMMENDED)
# -----------------------------------------------------------------------------
# Uses AWS credentials from environment or ~/.aws/credentials
# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key
# AWS_REGION_NAME=us-east-1
#
# Latest Claude models on Bedrock (Dec 2025):
# - bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0  (Claude Sonnet 4.5 - LATEST)
# - bedrock/anthropic.claude-opus-4-5-20251101-v1:0   (Claude Opus 4.5)
# - bedrock/anthropic.claude-haiku-4-5-20251001-v1:0  (Claude Haiku 4.5)
# - bedrock/amazon.titan-embed-text-v2:0
#
# To use Bedrock Claude Sonnet 4.5, set:
# DEFAULT_LLM_MODEL=bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0
# BEDROCK_EMBEDDING_MODEL=bedrock/amazon.titan-embed-text-v2:0

# -----------------------------------------------------------------------------
# Option 4: Google Cloud Vertex AI
# -----------------------------------------------------------------------------
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
# VERTEX_PROJECT=your-gcp-project-id
# VERTEX_LOCATION=us-central1
#
# Models (use vertex_ai/ prefix):
# - vertex_ai/gemini-3-pro-preview (Gemini 3 Pro - LATEST, 1M context)
#
# To use Vertex AI, set:
# DEFAULT_LLM_MODEL=vertex_ai/gemini-3-pro-preview
# VERTEX_EMBEDDING_MODEL=vertex_ai/text-embedding-004

# -----------------------------------------------------------------------------
# Option 5: Google AI Studio (Gemini 3 Pro - RECOMMENDED)
# -----------------------------------------------------------------------------
# GEMINI_API_KEY=your-gemini-api-key
#
# Latest Gemini models (Dec 2025):
# - gemini/gemini-3-pro-preview (Gemini 3 Pro - LATEST, 1M context, Nov 2025)
# - gemini/gemini-2.5-flash (Fast, 1M context)
#
# Embedding models:
# - text-embedding-004 (768 dimensions, latest)
#
# Get API key: https://aistudio.google.com/apikey
# Docs: https://ai.google.dev/gemini-api/docs

# -----------------------------------------------------------------------------
# Option 6: Anthropic (Claude)
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxx
# Models: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
# Note: Anthropic doesn't have embedding models, use with OpenAI/other for embeddings

# -----------------------------------------------------------------------------
# Option 7: OpenRouter (Access 100+ models via single API)
# -----------------------------------------------------------------------------
# OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxx
#
# Models (use openrouter/ prefix):
# - openrouter/anthropic/claude-3.5-sonnet
# - openrouter/openai/gpt-4o
# - openrouter/google/gemini-pro
# - openrouter/meta-llama/llama-3.1-405b-instruct
#
# Get API key: https://openrouter.ai/keys
# Browse models: https://openrouter.ai/models

# -----------------------------------------------------------------------------
# Default Provider Settings (Dec 2025 - Latest Models)
# -----------------------------------------------------------------------------
# Recommended: Use Gemini 3 Pro (best price/performance)
DEFAULT_LLM_PROVIDER=gemini
DEFAULT_LLM_MODEL=gemini/gemini-3-pro-preview

# Examples for other providers (LATEST models):
# DEFAULT_LLM_MODEL=gemini/gemini-3-pro-preview                    # Gemini 3 Pro (1M context)
# DEFAULT_LLM_MODEL=bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0  # Claude Sonnet 4.5
# DEFAULT_LLM_MODEL=azure/gpt-5.1-codex-mini                       # Azure Codex 5.1 Mini (400K)
# DEFAULT_LLM_MODEL=openai/gpt-5                                   # GPT-5

# Embedding model override (optional - auto-detected based on provider)
# EMBEDDING_MODEL=openai/text-embedding-3-small
# EMBEDDING_MODEL=azure/text-embedding-ada-002
# EMBEDDING_MODEL=bedrock/amazon.titan-embed-text-v2:0
# EMBEDDING_MODEL=vertex_ai/text-embedding-004

# Celery
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# Feature Flags
# Use PostgreSQL as single source of truth for embeddings state (new architecture)
# Set to false to fall back to legacy Redis-based state management
USE_POSTGRES_EMBEDDINGS_STATE=true

# Sandbox (for Docker deployment only)
# When running Celery inside Docker, configure these paths:
# SANDBOX_ROOT_DIR: Base directory for sandbox workdirs inside Celery container
# HOST_SANDBOX_PATH: Corresponding path on Docker host for volume mounting
# For local development, leave these empty (defaults to /tmp)
SANDBOX_ROOT_DIR=
HOST_SANDBOX_PATH=
# Example for Docker deployment:
# SANDBOX_ROOT_DIR=/app/sandbox_data
# HOST_SANDBOX_PATH=/absolute/path/to/project/sandbox_data

# Vector Retention Policy (commit-aware RAG cleanup)
# ⚠️ DISABLED BY DEFAULT - Enable only if you understand the implications!
# When enabled, old analysis vectors are automatically deleted to save storage.
# Vectors are retained for analyses that pass EITHER condition:
# - Within the last N completed analyses per repository
# - Created within the last X days
# Pinned analyses are NEVER deleted regardless of retention policy.
VECTOR_RETENTION_ENABLED=false
VECTOR_RETENTION_MAX_ANALYSES=50
VECTOR_RETENTION_MAX_DAYS=180
# To enable automatic cleanup:
# VECTOR_RETENTION_ENABLED=true

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000/v1
NEXT_PUBLIC_APP_URL=http://localhost:3000
NEXT_PUBLIC_GITHUB_CLIENT_ID=Iv1.xxxxxxxxxxxx
SESSION_SECRET=your-session-secret-at-least-32-chars-long
