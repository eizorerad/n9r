# –ü–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

## üéØ –î–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Ä–µ—à–µ–Ω–∏—è

### –í–∞—Ä–∏–∞–Ω—Ç A: Quick Fixes (1-2 –¥–Ω—è, –Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫)
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º.

### –í–∞—Ä–∏–∞–Ω—Ç B: –ü–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ (5-7 –¥–Ω–µ–π, —Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫)
–°–∏—Å—Ç–µ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π.

---

## üöÄ –í–∞—Ä–∏–∞–Ω—Ç A: Quick Fixes (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –°–ù–ê–ß–ê–õ–ê)

### –¶–µ–ª—å
–ò—Å–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏, —á—Ç–æ–±—ã —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ.

### Fix #1: –ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å embeddings task –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ

**–§–∞–π–ª:** `frontend/hooks/use-analysis-stream.ts`
**–°—Ç—Ä–æ–∫–∏:** 302-311
**–î–µ–π—Å—Ç–≤–∏–µ:** –£–¥–∞–ª–∏—Ç—å –±–ª–æ–∫ –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–±–∞–≤–ª—è–µ—Ç embeddings task

```typescript
// –£–î–ê–õ–ò–¢–¨ –≤–µ—Å—å —ç—Ç–æ—Ç –±–ª–æ–∫:
const embeddingsTaskId = `embeddings-${repositoryId}`
console.log('[Analysis Complete] Adding embeddings task:', embeddingsTaskId)
addTask({
  id: embeddingsTaskId,
  type: 'embeddings',
  repositoryId,
  status: 'pending',
  progress: 0,
  stage: 'waiting',
  message: 'Waiting for embeddings to start...',
})
console.log('[Analysis Complete] Embeddings task added')
```

**–ü–æ—á–µ–º—É:** Task –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ semantic-analysis-section –∫–æ–≥–¥–∞ polling —É–≤–∏–¥–∏—Ç –†–ï–ê–õ–¨–ù–´–ô status='running' –æ—Ç backend.

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –Ω–µ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å "ghost" embeddings task –∫–æ—Ç–æ—Ä—ã–π —Å—Ä–∞–∑—É –∏—Å—á–µ–∑–∞–µ—Ç.

**–í—Ä–µ–º—è:** 30 –º–∏–Ω—É—Ç

---

### Fix #2: Backend –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç "unknown" –∫–æ–≥–¥–∞ –Ω–µ —É–≤–µ—Ä–µ–Ω

**–§–∞–π–ª:** `backend/app/api/v1/semantic.py`
**–°—Ç—Ä–æ–∫–∏:** 1169-1207
**–î–µ–π—Å—Ç–≤–∏–µ:** –ò–∑–º–µ–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É fallback

–í–º–µ—Å—Ç–æ –ø–æ–ø—ã—Ç–∫–∏ —É–≥–∞–¥–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ Qdrant –≤–µ–∫—Ç–æ—Ä–∞–º, —á–µ—Å—Ç–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å "unknown" –∫–æ–≥–¥–∞:
- –ù–µ—Ç Redis state
- –í Qdrant –µ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ã
- –ù–û semantic_cache = NULL (–∑–Ω–∞—á–∏—Ç –µ—â—ë –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è)

**–ö–æ–¥ –∏–∑–º–µ–Ω–µ–Ω–∏—è:**

```python
# –ö–æ–≥–¥–∞ –Ω–µ—Ç Redis state –Ω–æ –µ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –≤ Qdrant:
if count.count > 0:
    # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ analysis —Å –≥–æ—Ç–æ–≤—ã–º semantic_cache
    from app.models.analysis import Analysis
    
    last_cached = await db.execute(
        select(Analysis)
        .where(
            Analysis.repository_id == repository_id,
            Analysis.semantic_cache.isnot(None),
        )
        .order_by(Analysis.created_at.desc())
        .limit(1)
    )
    cached_analysis = last_cached.scalar_one_or_none()
    
    if cached_analysis and cached_analysis.semantic_cache:
        # –ï—Å—Ç—å –≥–æ—Ç–æ–≤—ã–π cache - –º–æ–∂–µ–º –≤–µ—Ä–Ω—É—Ç—å completed
        return EmbeddingStatusResponse(
            repository_id=str(repository_id),
            status="completed",
            stage="completed",
            progress=100,
            message=f"{count.count} vectors available",
            chunks_processed=count.count,
            vectors_stored=count.count,
            analysis_id=str(cached_analysis.id),
        )
    else:
        # –í–µ–∫—Ç–æ—Ä—ã –µ—Å—Ç—å, –Ω–æ cache –ù–ï –≥–æ—Ç–æ–≤ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º unknown
        return EmbeddingStatusResponse(
            repository_id=str(repository_id),
            status="unknown",
            stage="computing",
            progress=50,
            message="Vectors exist, computing semantic analysis...",
            chunks_processed=count.count,
            vectors_stored=count.count,
            analysis_id=None,
        )
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Frontend –Ω–µ –±—É–¥–µ—Ç –≤–∏–¥–µ—Ç—å –ª–æ–∂–Ω—ã–π "completed" –ø–æ–∫–∞ semantic_cache –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ –≥–æ—Ç–æ–≤.

**–í—Ä–µ–º—è:** 1 —á–∞—Å

---

### Fix #3: Frontend –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç "unknown" status

**–§–∞–π–ª:** `frontend/components/semantic-analysis-section.tsx`
**–°—Ç—Ä–æ–∫–∏:** 214
**–î–µ–π—Å—Ç–≤–∏–µ:** –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É unknown status

```typescript
const isNone = data.status === 'none'
const isUnknown = data.status === 'unknown'

// –ü–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ isStaleStatus, –¥–æ–±–∞–≤–∏—Ç—å:
if (isUnknown) {
  console.log('[SemanticAnalysis] Backend computing state, continue polling')
  if (taskExists) {
    updateTask(taskId, {
      status: 'running',
      stage: 'computing',
      message: 'Computing semantic analysis...',
      progress: 50,
    })
  }
  return // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º polling
}
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Frontend –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ.

**–í—Ä–µ–º—è:** 15 –º–∏–Ω—É—Ç

---

### Fix #4: –£–≤–µ–ª–∏—á–∏—Ç—å polling intervals

**–§–∞–π–ª:** `frontend/components/semantic-analysis-section.tsx`
**–°—Ç—Ä–æ–∫–∏:** 432-439
**–î–µ–π—Å—Ç–≤–∏–µ:** –ò–∑–º–µ–Ω–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã polling

```typescript
// –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã:
const shouldPollFast = isNowInProgress && pollCount <= 20
const shouldPollMedium = taskExists || isNone || pollCount <= 30
const shouldPollSlow = isNowCompleted || pollCount > 30

const newInterval = shouldPollSlow ? 10000 : 
                   (shouldPollFast ? 2000 : 5000)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–µ–Ω—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ backend, –º–µ–Ω—å—à–µ –ª–∏—à–Ω–∏—Ö UI updates.

**–í—Ä–µ–º—è:** 10 –º–∏–Ω—É—Ç

---

### Fix #5: Debounce semantic cache refresh

**–§–∞–π–ª:** `frontend/components/semantic-analysis-section.tsx`
**–°—Ç—Ä–æ–∫–∏:** 385-391
**–î–µ–π—Å—Ç–≤–∏–µ:** –î–æ–±–∞–≤–∏—Ç—å debouncing —Å cancellation

```typescript
// –î–æ–±–∞–≤–∏—Ç—å ref –¥–ª—è timeout:
const refreshTimeoutRef = useRef<NodeJS.Timeout>()

// –í cleanup effect:
useEffect(() => {
  return () => {
    if (refreshTimeoutRef.current) {
      clearTimeout(refreshTimeoutRef.current)
    }
  }
}, [])

// –í –ª–æ–≥–∏–∫–µ refresh:
if (needsRefresh) {
  console.log('[SemanticAnalysis] Triggering cache refresh after delay...')
  
  // Cancel previous timeout –µ—Å–ª–∏ –µ—Å—Ç—å
  if (refreshTimeoutRef.current) {
    clearTimeout(refreshTimeoutRef.current)
  }
  
  // Schedule new refresh —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
  refreshTimeoutRef.current = setTimeout(() => {
    console.log('[SemanticAnalysis] Executing cache refresh now')
    setRefreshKey(k => k + 1)
    refreshTimeoutRef.current = undefined
  }, 2000)  // –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 500ms –¥–æ 2000ms
}
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Cache —É—Å–ø–µ–≤–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ fetch, –º–µ–Ω—å—à–µ –ª–∏—à–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

**–í—Ä–µ–º—è:** 20 –º–∏–Ω—É—Ç

---

## üìä –ò—Ç–æ–≥–æ Quick Fixes

| Fix | –§–∞–π–ª | –í—Ä–µ–º—è | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|-----|------|-------|-----------|
| #1 | use-analysis-stream.ts | 30 –º–∏–Ω | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| #2 | semantic.py | 1 —á–∞—Å | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| #3 | semantic-analysis-section.tsx | 15 –º–∏–Ω | üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| #4 | semantic-analysis-section.tsx | 10 –º–∏–Ω | üü° –í—ã—Å–æ–∫–∏–π |
| #5 | semantic-analysis-section.tsx | 20 –º–∏–Ω | üü° –í—ã—Å–æ–∫–∏–π |

**–û–±—â–µ–µ –≤—Ä–µ–º—è: 2-3 —á–∞—Å–∞**

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –Ω–µ "–º–∏–≥–∞–µ—Ç" (–Ω–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è/–∏—Å—á–µ–∑–∞–µ—Ç)
- ‚úÖ –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–∂–Ω—ã–π "completed"
- ‚úÖ –ú–µ–Ω—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ backend (–º–µ–Ω—å—à–µ polling)
- ‚úÖ UI –º–µ–Ω—å—à–µ –¥—ë—Ä–≥–∞–µ—Ç—Å—è
- ‚ö†Ô∏è –í—Å—ë –µ—â—ë –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–µ–¥–∫–∏–µ edge cases

---

## üèóÔ∏è –í–∞—Ä–∏–∞–Ω—Ç B: –ü–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ (–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ)

### –ó–∞—á–µ–º –Ω—É–∂–µ–Ω –ø–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥?

Quick fixes —Ä–µ—à–∞—é—Ç 80-90% –ø—Ä–æ–±–ª–µ–º, –Ω–æ:
- –û—Å—Ç–∞—é—Ç—Å—è edge cases –∫–æ–≥–¥–∞ Redis TTL –∏—Å—Ç–µ–∫–∞–µ—Ç
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤—Å—ë –µ—â—ë —Å–ª–æ–∂–Ω–∞—è (multiple sources of truth)
- –¢—Ä—É–¥–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ features
- –¢—Ä—É–¥–Ω–æ –¥–µ–±–∞–∂–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—ã

### –ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è

#### 1. PostgreSQL –∫–∞–∫ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π source of truth

**–ù–æ–≤—ã–µ –ø–æ–ª—è –≤ Analysis table:**
```sql
embeddings_status VARCHAR(20) DEFAULT 'none'
embeddings_progress INTEGER DEFAULT 0  
embeddings_message TEXT
embeddings_started_at TIMESTAMP
embeddings_completed_at TIMESTAMP
embeddings_vectors_count INTEGER DEFAULT 0
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- Permanent storage (–Ω–µ —Ç–µ—Ä—è–µ—Ç—Å—è –ø—Ä–∏ restart)
- –ú–æ–∂–Ω–æ query —Ç–æ—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª—é–±–æ–≥–æ analysis
- Redis –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è live updates (optional)

#### 2. –î–æ–±–∞–≤–∏—Ç—å analysis_id –≤ Qdrant –≤–µ–∫—Ç–æ—Ä—ã

**–ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ payload:**
```json
{
  "repository_id": "499bb544-36bb-45dd-823e-fbf4d45abd4b",
  "commit_sha": "16e04f9afdd886b5cfc51862deb8f169d203cbff",
  "analysis_id": "6aa4e309-7f82-4a26-a9cf-2652d1862b19",
  "file_path": "backend/app/main.py",
  "language": "python",
  "chunk_type": "function",
  "name": "analyze_code",
  "content": "def analyze_code():\n    pass"
}
```

**–ú–∏–≥—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤:**
- Script –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç analysis –ø–æ repository_id + commit_sha
- –û–±–Ω–æ–≤–ª—è–µ—Ç payload –∫–∞–∂–¥–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞

#### 3. Embeddings worker –æ–±–Ω–æ–≤–ª—è–µ—Ç PostgreSQL

**–ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ:**
```python
UPDATE analyses 
SET embeddings_status = 'running',
    embeddings_started_at = NOW(),
    embeddings_progress = 0
WHERE id = analysis_id
```

**–ü—Ä–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ:**
```python
UPDATE analyses
SET embeddings_progress = 45,
    embeddings_message = 'Embedding batch 10/20...',
    embeddings_vectors_count = 500
WHERE id = analysis_id
```

**–ü—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏:**
```python
UPDATE analyses
SET embeddings_status = 'completed',
    embeddings_completed_at = NOW(),
    embeddings_progress = 100,
    embeddings_vectors_count = 1025
WHERE id = analysis_id
```

#### 4. –ù–æ–≤—ã–π —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π API endpoint

```
GET /analyses/{analysis_id}/embeddings-status
```

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
```json
{
  "analysis_id": "6aa4e309-...",
  "embeddings_status": "running",
  "embeddings_progress": 45,
  "embeddings_message": "Embedding batch 10/20...",
  "embeddings_vectors_count": 500,
  "semantic_cache_ready": false
}
```

**–õ–æ–≥–∏–∫–∞:** –ü—Ä–æ—Å—Ç–æ —á–∏—Ç–∞–µ—Ç –∏–∑ PostgreSQL. –ù–∏–∫–∞–∫–∏—Ö fallbacks, –Ω–∏–∫–∞–∫–∏—Ö —É–≥–∞–¥—ã–≤–∞–Ω–∏–π.

#### 5. Frontend —É–ø—Ä–æ—â–µ–Ω–∏–µ

**–ë–´–õ–û:** Manual polling —Å —Å–ª–æ–∂–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
**–°–¢–ê–õ–û:** React Query —Å auto-refetch

```typescript
const { data: embeddingsStatus } = useQuery({
  queryKey: ['embeddings', selectedAnalysisId],
  queryFn: () => api.getEmbeddingsStatus(selectedAnalysisId),
  enabled: !!selectedAnalysisId,
  refetchInterval: (data) => {
    // Refetch —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ
    if (data?.embeddings_status === 'running') return 2000
    if (data?.embeddings_status === 'completed' && !data?.semantic_cache_ready) return 5000
    return false // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å polling
  },
})

// Sync —Å progress store:
useEffect(() => {
  if (!embeddingsStatus) return
  
  if (embeddingsStatus.embeddings_status === 'running') {
    if (!hasTask(taskId)) {
      addTask({id: taskId, type: 'embeddings', ...embeddingsStatus})
    } else {
      updateTask(taskId, embeddingsStatus)
    }
  } else if (embeddingsStatus.embeddings_status === 'completed') {
    if (hasTask(taskId)) {
      updateTask(taskId, {status: 'completed', progress: 100})
      setTimeout(() => removeTask(taskId), 2000)
    }
  }
}, [embeddingsStatus])
```

---

## üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞

### –§–∞–∑–∞ 1: Backend Foundation (2-3 –¥–Ω—è)

#### Task 1.1: Database migration (2 —á–∞—Å–∞)

**–°–æ–∑–¥–∞—Ç—å:** `backend/alembic/versions/007_embeddings_tracking.py`

```python
"""Add embeddings tracking to Analysis table

Revision ID: 007
Revises: 006
Create Date: 2025-12-04
"""

from alembic import op
import sqlalchemy as sa

def upgrade():
    op.add_column('analyses', 
        sa.Column('embeddings_status', sa.String(20), 
                 server_default='none', nullable=False))
    op.add_column('analyses',
        sa.Column('embeddings_progress', sa.Integer, 
                 server_default='0', nullable=False))
    op.add_column('analyses',
        sa.Column('embeddings_message', sa.Text, nullable=True))
    op.add_column('analyses',
        sa.Column('embeddings_started_at', sa.DateTime, nullable=True))
    op.add_column('analyses',
        sa.Column('embeddings_completed_at', sa.DateTime, nullable=True))
    op.add_column('analyses',
        sa.Column('embeddings_vectors_count', sa.Integer, 
                 server_default='0', nullable=False))
    
    op.create_index('ix_analyses_embeddings_status', 
                   'analyses', ['embeddings_status'])

def downgrade():
    op.drop_index('ix_analyses_embeddings_status')
    op.drop_column('analyses', 'embeddings_status')
    op.drop_column('analyses', 'embeddings_progress')
    op.drop_column('analyses', 'embeddings_message')
    op.drop_column('analyses', 'embeddings_started_at')
    op.drop_column('analyses', 'embeddings_completed_at')
    op.drop_column('analyses', 'embeddings_vectors_count')
```

**–ó–∞–ø—É—Å—Ç–∏—Ç—å:** `cd backend && alembic upgrade head`

---

#### Task 1.2: Update Analysis model (30 –º–∏–Ω)

**–§–∞–π–ª:** `backend/app/models/analysis.py`

–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ –∫–ª–∞—Å—Å Analysis:

```python
from sqlalchemy.orm import Mapped, mapped_column
from sqlalchemy import String, Integer, Text, DateTime

class Analysis(Base):
    __tablename__ = "analyses"
    
    # Existing fields here
    
    # Embeddings tracking
    embeddings_status: Mapped[str] = mapped_column(String(20), default="none")
    embeddings_progress: Mapped[int] = mapped_column(Integer, default=0)
    embeddings_message: Mapped[str | None] = mapped_column(Text, nullable=True)
    embeddings_started_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)
    embeddings_completed_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)
    embeddings_vectors_count: Mapped[int] = mapped_column(Integer, default=0)
```

---

#### Task 1.3: Qdrant migration script (3 —á–∞—Å–∞)

**–°–æ–∑–¥–∞—Ç—å:** `backend/scripts/migrate_qdrant_add_analysis_id.py`

–°–∫—Ä–∏–ø—Ç –∫–æ—Ç–æ—Ä—ã–π:
1. –ß–∏—Ç–∞–µ—Ç –≤—Å–µ –≤–µ–∫—Ç–æ—Ä—ã –∏–∑ Qdrant
2. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ repository_id + commit_sha
3. –ù–∞—Ö–æ–¥–∏—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π Analysis –≤ PostgreSQL
4. –û–±–Ω–æ–≤–ª—è–µ—Ç payload.analysis_id –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞

**–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ—Å–ª–µ –¥–µ–ø–ª–æ—è:** `python backend/scripts/migrate_qdrant_add_analysis_id.py`

---

#### Task 1.4: –û–±–Ω–æ–≤–∏—Ç—å embeddings worker (4 —á–∞—Å–∞)

**–§–∞–π–ª:** `backend/app/workers/embeddings.py`

**–ò–∑–º–µ–Ω–µ–Ω–∏–µ #1:** –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –æ–±–Ω–æ–≤–ª—è—Ç—å PostgreSQL

```python
def generate_embeddings(self, repository_id: str, commit_sha: str,
                       files: list[dict], analysis_id: str) -> dict:
    
    logger.info(f"Generating embeddings for repository {repository_id}")
    
    # UPDATE PostgreSQL –ü–†–ò –°–¢–ê–†–¢–ï
    from app.core.database import get_sync_session
    from app.models.analysis import Analysis
    
    with get_sync_session() as db:
        analysis = db.get(Analysis, UUID(analysis_id))
        if analysis:
            analysis.embeddings_status = 'running'
            analysis.embeddings_started_at = datetime.utcnow()
            analysis.embeddings_progress = 0
            analysis.embeddings_message = 'Starting embeddings...'
            db.commit()
            logger.info(f"Updated analysis {analysis_id} embeddings_status to 'running'")
    
    # Helper function –¥–ª—è progress updates
    def publish_progress(stage: str, progress: int, message: str | None = None,
                        status: str = "running", chunks: int = 0, vectors: int = 0):
        # Update PostgreSQL
        with get_sync_session() as db:
            analysis = db.get(Analysis, UUID(analysis_id))
            if analysis:
                analysis.embeddings_progress = progress
                analysis.embeddings_message = message
                analysis.embeddings_vectors_count = vectors
                db.commit()
        
        # OPTIONAL: Publish to Redis –¥–ª—è real-time updates
        publish_embedding_progress(
            repository_id=repository_id,
            stage=stage,
            progress=progress,
            message=message,
            status=status,
            chunks_processed=chunks,
            vectors_stored=vectors,
            analysis_id=analysis_id,
        )
        
        self.update_state(state="PROGRESS", meta={"stage": stage, "progress": progress})
    
    try:
        publish_progress("initializing", 5, "Starting embedding generation...")
        
        chunker = get_code_chunker()
        from app.services.llm_gateway import get_llm_gateway
        llm = get_llm_gateway()
        qdrant = get_qdrant_client()
        
        # Generate chunks and embeddings (existing logic)
        
        # CREATE POINTS with analysis_id
        for chunk, embedding in chunk_embedding_pairs:
            point_id = f"{repository_id}_{chunk.file_path}_{chunk.line_start}".replace("/", "_").replace(".", "_")
            
            points.append(PointStruct(
                id=hash(point_id) % (2**63),
                vector=embedding,
                payload={
                    "repository_id": repository_id,
                    "commit_sha": commit_sha,
                    "analysis_id": analysis_id,  # –î–û–ë–ê–í–ò–¢–¨ analysis_id!
                    "file_path": chunk.file_path,
                    "language": chunk.language,
                    "chunk_type": chunk.chunk_type,
                    "name": chunk.name,
                    "line_start": chunk.line_start,
                    "line_end": chunk.line_end,
                    "parent_name": chunk.parent_name,
                    "docstring": chunk.docstring,
                    "content": chunk.content[:2000],
                    "token_estimate": chunk.token_estimate,
                    "level": chunk.level,
                    "qualified_name": chunk.qualified_name,
                    "cyclomatic_complexity": chunk.cyclomatic_complexity,
                    "line_count": chunk.line_count,
                    "cluster_id": None,
                }
            ))
        
        logger.info(f"Generated {len(points)} embedding vectors")
        publish_progress("indexing", 85, "Storing vectors in Qdrant...", 
                        chunks=len(all_chunks), vectors=len(points))
        
        # Store in Qdrant (existing logic)
        
        # Compute semantic cache (existing logic)
        semantic_cache = None
        if analysis_id and len(points) >= 5:
            publish_progress("semantic_analysis", 92, "Computing semantic analysis...",
                           chunks=len(all_chunks), vectors=len(points))
            try:
                semantic_cache = _compute_and_store_semantic_cache(
                    repository_id=repository_id,
                    analysis_id=analysis_id,
                )
            except Exception as e:
                logger.warning(f"Failed to compute semantic cache: {e}")
        
        # UPDATE PostgreSQL –ü–†–ò –ó–ê–í–ï–†–®–ï–ù–ò–ò
        with get_sync_session() as db:
            analysis = db.get(Analysis, UUID(analysis_id))
            if analysis:
                analysis.embeddings_status = 'completed'
                analysis.embeddings_completed_at = datetime.utcnow()
                analysis.embeddings_progress = 100
                analysis.embeddings_vectors_count = len(points)
                db.commit()
                logger.info(f"Updated analysis {analysis_id} embeddings_status to 'completed'")
        
        # Publish completion
        publish_progress("completed", 100, f"Generated {len(points)} embeddings",
                        status="completed", chunks=len(all_chunks), vectors=len(points))
        
        return {
            "repository_id": repository_id,
            "commit_sha": commit_sha,
            "chunks_processed": len(all_chunks),
            "vectors_stored": len(points),
            "status": "completed",
            "semantic_cache_computed": semantic_cache is not None,
        }
        
    except Exception as e:
        logger.error(f"Embedding generation failed: {e}")
        
        # UPDATE PostgreSQL ON ERROR
        with get_sync_session() as db:
            analysis = db.get(Analysis, UUID(analysis_id))
            if analysis:
                analysis.embeddings_status = 'error'
                analysis.embeddings_message = str(e)[:500]
                db.commit()
        
        publish_embedding_progress(
            repository_id=repository_id,
            stage="error",
            progress=0,
            message=str(e),
            status="error",
            analysis_id=analysis_id,
        )
        raise
```

---

#### Task 1.5: –ù–æ–≤—ã–π API endpoint (1 —á–∞—Å)

**–§–∞–π–ª:** `backend/app/api/v1/analyses.py`

–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π endpoint:

```python
class EmbeddingsStatusResponse(BaseModel):
    analysis_id: str
    embeddings_status: str
    embeddings_progress: int
    embeddings_message: str | None
    embeddings_vectors_count: int
    semantic_cache_ready: bool
    started_at: str | None
    completed_at: str | None

@router.get("/analyses/{analysis_id}/embeddings-status")
async def get_analysis_embeddings_status(
    analysis_id: UUID,
    db: DbSession,
    user: CurrentUser,
) -> EmbeddingsStatusResponse:
    """Get embeddings status for specific analysis.
    
    Source of truth: PostgreSQL Analysis table.
    No fallbacks, no guessing - just return exact state.
    """
    result = await db.execute(
        select(Analysis)
        .join(Repository)
        .where(
            Analysis.id == analysis_id,
            Repository.owner_id == user.id,
        )
    )
    analysis = result.scalar_one_or_none()
    
    if not analysis:
        raise HTTPException(404, "Analysis not found")
    
    return EmbeddingsStatusResponse(
        analysis_id=str(analysis.id),
        embeddings_status=analysis.embeddings_status or 'none',
        embeddings_progress=analysis.embeddings_progress or 0,
        embeddings_message=analysis.embeddings_message,
        embeddings_vectors_count=analysis.embeddings_vectors_count or 0,
        semantic_cache_ready=analysis.semantic_cache is not None,
        started_at=analysis.embeddings_started_at.isoformat() if analysis.embeddings_started_at else None,
        completed_at=analysis.embeddings_completed_at.isoformat() if analysis.embeddings_completed_at else None,
    )
```

---

### –§–∞–∑–∞ 2: Frontend Refactoring (2 –¥–Ω—è)

#### Task 2.1: –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –Ω–æ–≤—ã–π endpoint (1 —á–∞—Å)

**–§–∞–π–ª:** `frontend/components/semantic-analysis-section.tsx`

–ò–∑–º–µ–Ω–∏—Ç—å fetchStatus —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π endpoint:

```typescript
const fetchStatus = async (): Promise<EmbeddingStatus | null> => {
  if (!selectedAnalysisId) return null
  
  try {
    const response = await fetch(
      `${process.env.NEXT_PUBLIC_API_URL}/analyses/${selectedAnalysisId}/embeddings-status`,
      { headers: { 'Authorization': `Bearer ${token}` } }
    )
    
    if (response.ok) {
      const data = await response.json()
      return {
        repository_id: repositoryId,
        status: data.embeddings_status,
        stage: data.embeddings_status,
        progress: data.embeddings_progress,
        message: data.embeddings_message,
        chunks_processed: data.embeddings_vectors_count,
        vectors_stored: data.embeddings_vectors_count,
        analysis_id: data.analysis_id,
      }
    }
  } catch (error) {
    console.error('Failed to fetch status:', error)
  }
  return null
}
```

#### Task 2.2: –£–ø—Ä–æ—Å—Ç–∏—Ç—å polling logic (3 —á–∞—Å–∞)

**–§–∞–π–ª:** `frontend/components/semantic-analysis-section.tsx`

–£–±—Ä–∞—Ç—å –≤—Å—é —Å–ª–æ–∂–Ω—É—é –ª–æ–≥–∏–∫—É —Å isStaleStatus, taskExists checks.

–ù–æ–≤–∞—è —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞:

```typescript
const poll = async () => {
  if (!isMounted) return
  
  const data = await fetchStatus()
  if (!isMounted || !data) return
  
  setEmbeddingStatus(data)
  
  // –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ status
  const status = data.status
  const taskExists = hasTask(taskId)
  
  if (status === 'running') {
    if (!taskExists) {
      addTask({
        id: taskId,
        type: 'embeddings',
        repositoryId,
        status: 'running',
        progress: data.progress,
        stage: data.stage,
        message: data.message,
      })
    } else {
      updateTask(taskId, {
        status: 'running',
        progress: data.progress,
        stage: data.stage,
        message: data.message,
      })
    }
  } else if (status === 'completed') {
    if (taskExists) {
      updateTask(taskId, {
        status: 'completed',
        progress: 100,
        stage: 'completed',
        message: `${data.vectors_stored} vectors available`,
      })
      setTimeout(() => removeTask(taskId), 2000)
    }
    
    // Refresh cache –µ—Å–ª–∏ –Ω–µ –≥–æ—Ç–æ–≤
    if (!semanticCache?.is_cached) {
      setTimeout(() => setRefreshKey(k => k + 1), 2000)
    } else {
      // Cache –≥–æ—Ç–æ–≤ - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å polling
      if (intervalId) {
        clearInterval(intervalId)
        intervalId = null
      }
      return
    }
  }
  
  // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å polling –µ—Å–ª–∏ –≤—Å—ë –≥–æ—Ç–æ–≤–æ
  const allDone = status === 'completed' && semanticCache?.is_cached
  if (allDone && intervalId) {
    clearInterval(intervalId)
    intervalId = null
  }
}
```

#### Task 2.3: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - React Query (4 —á–∞—Å–∞)

**–§–∞–π–ª:** `frontend/components/semantic-analysis-section.tsx`

–ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏—Ç—å manual polling –Ω–∞ React Query –¥–ª—è –±–æ–ª–µ–µ —á–∏—Å—Ç–æ–≥–æ –∫–æ–¥–∞.

---

### –§–∞–∑–∞ 3: Testing & Rollout (1 –¥–µ–Ω—å)

#### Task 3.1: Integration tests (3 —á–∞—Å–∞)

–¢–µ—Å—Ç—ã –¥–ª—è:
- –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: analysis ‚Üí embeddings ‚Üí clustering ‚Üí cache ready
- Edge case: Redis TTL –∏—Å—Ç–µ–∫–∞–µ—Ç –≤–æ –≤—Ä–µ–º—è embeddings
- Edge case: Server restart –≤–æ –≤—Ä–µ–º—è embeddings
- Multiple analyses –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ

#### Task 3.2: Manual testing (2 —á–∞—Å–∞)

- –ó–∞–ø—É—Å—Ç–∏—Ç—å 5-10 analyses –ø–æ–¥—Ä—è–¥
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –Ω–∞ –≤—Å–µ—Ö —ç—Ç–∞–ø–∞—Ö
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ semantic cache –ø–æ—è–≤–ª—è–µ—Ç—Å—è
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –Ω–µ—Ç "ghost" tasks

#### Task 3.3: Production rollout (2 —á–∞—Å–∞)

1. Deploy backend —Å –º–∏–≥—Ä–∞—Ü–∏–µ–π
2. –ó–∞–ø—É—Å—Ç–∏—Ç—å Qdrant migration script
3. Deploy frontend
4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

–ü–æ—Å–ª–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –∏–∑–º–µ—Ä–∏—Ç—å:

### Quick Fixes (–í–∞—Ä–∏–∞–Ω—Ç A):
- ‚úÖ –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –Ω–µ "–º–∏–≥–∞–µ—Ç" (–ø–æ—è–≤–ª—è–µ—Ç—Å—è/–∏—Å—á–µ–∑–∞–µ—Ç)
- ‚úÖ –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–∂–Ω—ã–π "completed" –≤ –Ω–∞—á–∞–ª–µ
- ‚úÖ Polling requests < 20 –∑–∞ –≤—Ä–µ–º—è embeddings (–±—ã–ª–æ 30-50)
- ‚úÖ UI renders < 50 –∑–∞ –≤—Ä–µ–º—è embeddings (–±—ã–ª–æ 100+)

### –ü–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ (–í–∞—Ä–∏–∞–Ω—Ç B):
- ‚úÖ –í—Å–µ –≤—ã—à–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω–æ–µ +
- ‚úÖ Time to semantic_cache ready < 15 —Å–µ–∫ (–±—ã–ª–æ 20-40 —Å–µ–∫)
- ‚úÖ Zero false "completed" events
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ—Å–ª–µ Redis TTL expiry
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ—Å–ª–µ server restart
- ‚úÖ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å multiple analyses –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ

---

## ‚ö†Ô∏è –†–∏—Å–∫–∏

### Quick Fixes (–Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫):
- –ú–æ–≥—É—Ç –æ—Å—Ç–∞—Ç—å—Å—è —Ä–µ–¥–∫–∏–µ edge cases
- –ù–µ —Ä–µ—à–∞–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É

### –ü–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ (—Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫):
- –¢—Ä–µ–±—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ deploy backend + frontend
- Qdrant migration –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –Ω–∞ production
- –ù—É–∂–µ–Ω rollback –ø–ª–∞–Ω –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫

---

## üé¨ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –ù–µ–¥–µ–ª—è 1 (Quick Wins):

**–î–µ–Ω—å 1:**
- ‚úÖ Fix #1: –£–±—Ä–∞—Ç—å preemptive task (30 –º–∏–Ω)
- ‚úÖ Fix #2: Return "unknown" (1 —á–∞—Å)
- ‚úÖ Fix #3: Handle "unknown" (15 –º–∏–Ω)
- ‚úÖ Deploy –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (2 —á–∞—Å–∞)

**–î–µ–Ω—å 2:**
- ‚úÖ Fix #4: –£–≤–µ–ª–∏—á–∏—Ç—å intervals (10 –º–∏–Ω)
- ‚úÖ Fix #5: Debounce refresh (20 –º–∏–Ω)
- ‚úÖ Testing –∏ monitoring (3 —á–∞—Å–∞)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ –Ω–∞ 90%

### –ù–µ–¥–µ–ª—è 2 (–ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –∏–¥–µ–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞):

**–î–µ–Ω—å 3-4:**
- Database migration
- Analysis model update
- Embeddings worker update
- Qdrant migration script

**–î–µ–Ω—å 5-6:**
- –ù–æ–≤—ã–π API endpoint
- Frontend –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ
- –£–ø—Ä–æ—â–µ–Ω–∏–µ polling logic

**–î–µ–Ω—å 7:**
- Integration testing
- Production rollout
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

---

## üìù –î–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É

### –ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ (–ù–ï –ø–æ–º–æ–≥–ª–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é):

1. **–£–≤–µ–ª–∏—á–µ–Ω Qdrant timeout** ‚Üí —É–±—Ä–∞–ª timeout errors ‚úÖ
2. **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω cache endpoint** ‚Üí —É–±—Ä–∞–ª 404 –æ—à–∏–±–∫–∏ ‚úÖ
3. **Stale status detection** ‚Üí —á–∞—Å—Ç–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚ö†Ô∏è
4. **Qdrant fallback logic** ‚Üí —Å–æ–∑–¥–∞–ª –Ω–æ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã ‚ùå
5. **Commit timeline race fix** ‚Üí –ø–æ–º–æ–≥ –Ω–µ–º–Ω–æ–≥–æ ‚ö†Ô∏è

### –ö–æ—Ä–Ω–µ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞:

**–ü—Ä–æ–±–ª–µ–º–∞:** Qdrant –Ω–µ —Ö—Ä–∞–Ω–∏—Ç analysis_id –≤ –≤–µ–∫—Ç–æ—Ä–∞—Ö. –ö–æ–≥–¥–∞ Redis TTL –∏—Å—Ç–µ–∫–∞–µ—Ç –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, backend –Ω–µ –º–æ–∂–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫–æ–º—É analysis –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –≤–µ–∫—Ç–æ—Ä—ã. –û–Ω –ø—ã—Ç–∞–µ—Ç—Å—è —É–≥–∞–¥–∞—Ç—å ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π status ‚Üí frontend –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–∂–Ω—ã–π "completed" ‚Üí –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –º–∏–≥–∞–µ—Ç.

### –ß—Ç–æ –¥–µ–ª–∞—Ç—å:

**–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ (—Å–µ–≥–æ–¥–Ω—è):** –°–¥–µ–ª–∞—Ç—å Quick Fixes #1-3 (2 —á–∞—Å–∞) - —ç—Ç–æ —Ä–µ—à–∏—Ç 80% –ø—Ä–æ–±–ª–µ–º.

**–ù–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ:** –°–¥–µ–ª–∞—Ç—å Quick Fixes #4-5 (30 –º–∏–Ω) - —É–ª—É—á—à–∏—Ç UX.

**–ù–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é):** –ü–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ —Å PostgreSQL tracking –∏ analysis_id –≤ Qdrant - —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏ —Ä–∞—Å—à–∏—Ä—è–µ–º–æ–π.

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã:

Backend:
- `backend/app/api/v1/semantic.py` - embedding-status endpoint —Å –ø—Ä–æ–±–ª–µ–º–Ω–æ–π fallback –ª–æ–≥–∏–∫–æ–π
- `backend/app/workers/embeddings.py` - worker –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç PostgreSQL
- `backend/app/models/analysis.py` - –Ω—É–∂–Ω—ã –Ω–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è tracking

Frontend:
- `frontend/hooks/use-analysis-stream.ts` - preemptive task creation (—Å—Ç—Ä–æ–∫–∞ 302)
- `frontend/components/semantic-analysis-section.tsx` - —Å–ª–æ–∂–Ω—ã–π polling (—Å—Ç—Ä–æ–∫–∏ 162-453)

### –î–æ–∫—É–º–µ–Ω—Ç—ã:
- `ARCHITECTURE_ANALYSIS.md` - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- `IMPLEMENTATION_PLAN.md` - —ç—Ç–æ—Ç –ø–ª–∞–Ω —Å –ø–æ—à–∞–≥–æ–≤—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏